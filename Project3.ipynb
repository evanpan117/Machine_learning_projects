{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haojie Pan \n",
    "CSPS 483\n",
    "Prof. Avery\n",
    "10/21/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Visualization Libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#To plot the graph embedded in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  \\\n",
      "0  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3  396.90   \n",
      "1   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8  396.90   \n",
      "2   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8  392.83   \n",
      "3   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7  394.63   \n",
      "4   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7  396.90   \n",
      "\n",
      "   LSTAT  PRICE  \n",
      "0   4.98   24.0  \n",
      "1   9.14   21.6  \n",
      "2   4.03   34.7  \n",
      "3   2.94   33.4  \n",
      "4   5.33   36.2  \n",
      "0    0.00632\n",
      "1    0.02731\n",
      "2    0.02729\n",
      "3    0.03237\n",
      "4    0.06905\n",
      "Name: CRIM, dtype: float64\n",
      "               ZN       INDUS        CHAS         NOX          RM         AGE  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    11.363636   11.136779    0.069170    0.554695    6.284634   68.574901   \n",
      "std     23.322453    6.860353    0.253994    0.115878    0.702617   28.148861   \n",
      "min      0.000000    0.460000    0.000000    0.385000    3.561000    2.900000   \n",
      "25%      0.000000    5.190000    0.000000    0.449000    5.885500   45.025000   \n",
      "50%      0.000000    9.690000    0.000000    0.538000    6.208500   77.500000   \n",
      "75%     12.500000   18.100000    0.000000    0.624000    6.623500   94.075000   \n",
      "max    100.000000   27.740000    1.000000    0.871000    8.780000  100.000000   \n",
      "\n",
      "              DIS         RAD         TAX     PTRATIO           B       LSTAT  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.795043    9.549407  408.237154   18.455534  356.674032   12.653063   \n",
      "std      2.105710    8.707259  168.537116    2.164946   91.294864    7.141062   \n",
      "min      1.129600    1.000000  187.000000   12.600000    0.320000    1.730000   \n",
      "25%      2.100175    4.000000  279.000000   17.400000  375.377500    6.950000   \n",
      "50%      3.207450    5.000000  330.000000   19.050000  391.440000   11.360000   \n",
      "75%      5.188425   24.000000  666.000000   20.200000  396.225000   16.955000   \n",
      "max     12.126500   24.000000  711.000000   22.000000  396.900000   37.970000   \n",
      "\n",
      "            PRICE  \n",
      "count  506.000000  \n",
      "mean    22.532806  \n",
      "std      9.197104  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "#question 1-2\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "#print(boston.DESCR)\n",
    "\n",
    "bos = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "target = bos['CRIM']\n",
    "target.columns = ['CRIM']\n",
    "bos = bos.drop('CRIM', axis=1)\n",
    "bos['PRICE'] = boston.target\n",
    "\n",
    "print(bos.head())\n",
    "print(target.head())\n",
    "print(bos.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  PTRATIO  \\\n",
      "477   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0     20.2   \n",
      "15    0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0     21.0   \n",
      "332  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0     16.9   \n",
      "423   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0     20.2   \n",
      "19    0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0     21.0   \n",
      "\n",
      "          B  LSTAT  PRICE  \n",
      "477  349.48  24.91   12.0  \n",
      "15   395.62   8.47   19.9  \n",
      "332  362.25   7.83   19.4  \n",
      "423    2.52  23.29   13.4  \n",
      "19   390.95  11.28   18.2  \n"
     ]
    }
   ],
   "source": [
    "#question 3\n",
    "x_train, x_test, y_train, y_test = train_test_split(bos,target,test_size=0.2, random_state=42)\n",
    "print(x_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404, 1)\n",
      "w0 = [17.84434424]\n",
      "w1 = [ 4.34305474e-02 -2.88549625e-02 -9.69518283e-01 -1.17920684e+01\n",
      "  5.27133931e-01  1.07425446e-02 -1.00733277e+00  6.22515728e-01\n",
      " -3.68914965e-03 -3.04674637e-01 -5.21809725e-03  3.25370620e-02\n",
      " -2.33271552e-01]\n"
     ]
    }
   ],
   "source": [
    "#question 4\n",
    "print(x_train.shape)\n",
    "y_train1 = np.array(y_train).reshape([-1, 1])\n",
    "print(y_train1.shape)\n",
    "\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train, y_train1)\n",
    "\n",
    "print(f'w0 = {lm.intercept_}')\n",
    "print(f'w1 = {lm.coef_[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  44.65335182986894\n",
      "testing loss:  24.441976679474887\n"
     ]
    }
   ],
   "source": [
    "#question 5\n",
    "y_train_predict = lm.predict(x_train)\n",
    "y_test_predict = lm.predict(x_test)\n",
    "\n",
    "train_loss = mean_squared_error(y_train, y_train_predict)\n",
    "test_loss = mean_squared_error(y_test, y_test_predict)\n",
    "print('training loss: ', train_loss)\n",
    "print('testing loss: ', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.4316865149963002\n",
      "testing score:  0.5564085223708037\n"
     ]
    }
   ],
   "source": [
    "#question 6\n",
    "train_score = lm.score(x_train, y_train, sample_weight = None)\n",
    "test_score = lm.score(x_test, y_test, sample_weight = None)\n",
    "\n",
    "print('training score: ', train_score)\n",
    "print('testing score: ', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: our model did not fit training data very well, but fit the test data better. That is good luck.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 105)\n",
      "(102, 105)\n"
     ]
    }
   ],
   "source": [
    "#question 7\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x_train_degree1 = x_train\n",
    "x_test_degree1 = x_test\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "x_train_degree2 = poly.fit_transform(x_train_degree1)\n",
    "x_test_degree2 = poly.fit_transform(x_test_degree1)\n",
    "\n",
    "print(x_train_degree2.shape)\n",
    "print(x_test_degree2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "lm_degree2 = LinearRegression()\n",
    "lm_degree2.fit(x_train_degree2, y_train1)\n",
    "\n",
    "#print(f'w0 = {lm_degree2.intercept_}')\n",
    "#print(f'w1 = {lm_degree2.coef_[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  25.537504616305778\n",
      "testing loss:  26.262397585177045\n"
     ]
    }
   ],
   "source": [
    "#get MSE\n",
    "y_train_degree2_predict = lm_degree2.predict(x_train_degree2)\n",
    "y_test_degree2_predict = lm_degree2.predict(x_test_degree2)\n",
    "\n",
    "train_degree2_loss = mean_squared_error(y_train, y_train_degree2_predict)\n",
    "test_degree2_loss = mean_squared_error(y_test, y_test_degree2_predict)\n",
    "print('training loss: ', train_degree2_loss)\n",
    "print('testing loss: ', test_degree2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.6749783016941909\n",
      "testing score:  0.5233701470357345\n"
     ]
    }
   ],
   "source": [
    "#get scores\n",
    "train_degree2_score = lm_degree2.score(x_train_degree2, y_train, sample_weight = None)\n",
    "test_degree2_score = lm_degree2.score(x_test_degree2, y_test, sample_weight = None)\n",
    "\n",
    "print('training score: ', train_degree2_score)\n",
    "print('testing score: ', test_degree2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The training loss is reduced and the test loss is increased which means we are overfited or the degree 1 model got lucky.  \n",
    "    Training score is improved a lot which means this model fits the data better. The testing score is lower than training score which means our model is normal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(normalize=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 8\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#train model\n",
    "clf = Ridge(alpha=1.0, normalize = True)\n",
    "clf.fit(x_train_degree2, y_train1)\n",
    "\n",
    "#print(f'w0 = {clf.intercept_}')\n",
    "#print(f'w1 = {clf.coef_[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  41.41944010689912\n",
      "testing loss:  19.704582974781374\n"
     ]
    }
   ],
   "source": [
    "#get MSE\n",
    "y_train_degree2_predict = clf.predict(x_train_degree2)\n",
    "y_test_degree2_predict = clf.predict(x_test_degree2)\n",
    "\n",
    "train_degree2_loss = mean_squared_error(y_train, y_train_degree2_predict)\n",
    "test_degree2_loss = mean_squared_error(y_test, y_test_degree2_predict)\n",
    "print('training loss: ', train_degree2_loss)\n",
    "print('testing loss: ', test_degree2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.4728452537283371\n",
      "testing score:  0.6423863260948761\n"
     ]
    }
   ],
   "source": [
    "#get scores\n",
    "train_degree2_score = clf.score(x_train_degree2, y_train, sample_weight = None)\n",
    "test_degree2_score = clf.score(x_test_degree2, y_test, sample_weight = None)\n",
    "\n",
    "print('training score: ', train_degree2_score)\n",
    "print('testing score: ', test_degree2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: This model has the similar loss values as degree 1 model. It means this model puts more weights on the one degree features. This model got the highest testing score so far which means the regression model explains the relationship between x and y pretty good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.6665615784105534\n",
      "test score:  0.67121828001995\n"
     ]
    }
   ],
   "source": [
    "#question 9\n",
    "from sklearn.linear_model import RidgeCV\n",
    "clf = RidgeCV(alphas=[1]).fit(x_train_degree2, y_train1)\n",
    "print('training score: ',clf.score(x_train_degree2, y_train1, sample_weight = None))\n",
    "print('test score: ',clf.score(x_test_degree2, y_test, sample_weight = None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  26.198820801749577\n",
      "testing loss:  18.11593670676307\n"
     ]
    }
   ],
   "source": [
    "#get MSE\n",
    "y_train_degree2_predict = clf.predict(x_train_degree2)\n",
    "y_test_degree2_predict = clf.predict(x_test_degree2)\n",
    "\n",
    "train_degree2_loss = mean_squared_error(y_train, y_train_degree2_predict)\n",
    "test_degree2_loss = mean_squared_error(y_test, y_test_degree2_predict)\n",
    "print('training loss: ', train_degree2_loss)\n",
    "print('testing loss: ', test_degree2_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I got the best test score at alpha = 1. Both training and test loss get improved. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
